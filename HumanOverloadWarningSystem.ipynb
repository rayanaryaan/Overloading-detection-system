{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc72f0d",
   "metadata": {},
   "source": [
    "# Overloading Warning System\n",
    "### Rayan Aryaan\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "03b8b883",
   "metadata": {},
   "source": [
    "#installing the required components\n",
    "!pip -q install opencv-python\n",
    "# !pip -q install dlib\n",
    "#install dlib using conda prompt runs with admin permission using command: conda install -c conda-forge dlib\n",
    "!pip -q install numpy\n",
    "!pip -q install matplotlib\n",
    "!pip -q install imutils\n",
    "!pip -q install pandas\n",
    "!pip -q install beepy\n",
    "!pip -q install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9375d9a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03b58421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloudxlab.com/blog/object-detection-yolo-and-python-pydarknet/\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils.video import FPS\n",
    "from imutils.video import VideoStream\n",
    "import pandas as pd\n",
    "import re\n",
    "import beepy as beep\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "411cfb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project constants\n",
    "TOTAL_BEARING_CAPACITY = 150 # Change this value based on requirement or pass this as parameter\n",
    "playing_alert = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5447ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo models related pre-trained data files (Object detection including human)\n",
    "LABELS_FILE='data/coco.names'\n",
    "CONFIG_FILE='cfg/yolov3.cfg'\n",
    "WEIGHTS_FILE='Models/yolov3.weights'\n",
    "CONFIDENCE_THRESHOLD=0.3\n",
    "LABELS = open(LABELS_FILE).read().strip().split(\"\\n\")\n",
    "\n",
    "# Generate random colors for labels\n",
    "np.random.seed(4)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68da54d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Model \n",
    "AGE_WEIGHTS = \"Models/age_deploy.prototxt\"\n",
    "AGE_CONFIG = \"Models/age_net.caffemodel\"\n",
    "\n",
    "# Model requirements for image\n",
    "AGE_LIST = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
    "        '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "MODEL_MEAN = (78.4263377603, 87.7689143744, 114.895847746)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "955ad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gender model architecture\n",
    "# https://drive.google.com/open?id=1W_moLzMlGiELyPxWiYQJ9KFaXroQ_NFQ\n",
    "GENDER_MODEL = 'Models/gender_deploy.prototxt' # deploy_gender.prototxt'\n",
    "# The gender model pre-trained weights\n",
    "# https://drive.google.com/open?id=1AW3WduLk1haTVAxHOkVS_BEzel1WXQHP\n",
    "GENDER_PROTO = 'Models/gender_net.caffemodel'\n",
    "# Each Caffe Model impose the shape of the input image also image preprocessing is required like mean\n",
    "# substraction to eliminate the effect of illunination changes\n",
    "# Represent the gender classes\n",
    "GENDER_LIST = ['Male', 'Female']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349ea9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# play alert sound\n",
    "def play_warning():\n",
    "    global playing_alert\n",
    "    playing_alert = True\n",
    "    for ii in range(5,7): \n",
    "        beep.beep(ii)\n",
    "    playing_alert = False\n",
    "\n",
    "def play_alert_sound():\n",
    "    global playing_alert\n",
    "    if not playing_alert:\n",
    "        thread = Thread(target=play_warning)\n",
    "        thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "098447e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_lower_limit</th>\n",
       "      <th>age_upper_limit</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Male</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Male</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>Male</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>Male</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Female</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Female</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>Female</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>Female</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>Female</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>Female</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_lower_limit  age_upper_limit  gender  weight\n",
       "0                 0                3    Male      10\n",
       "1                 4                6    Male      18\n",
       "2                 7               12    Male      35\n",
       "3                13               20    Male      58\n",
       "4                21               32    Male      60\n",
       "5                33               43    Male      65\n",
       "6                44               53    Male      68\n",
       "7                54              100    Male      60\n",
       "8                 0                3  Female       9\n",
       "9                 4                6  Female      16\n",
       "10                7               12  Female      30\n",
       "11               13               20  Female      48\n",
       "12               21               32  Female      50\n",
       "13               33               43  Female      51\n",
       "14               44               53  Female      53\n",
       "15               54              100  Female      55"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weigth predictor dataframe (hardcoded as of now)\n",
    "df = pd.read_csv(\"age_gender_wt_mapper.csv\")\n",
    "# Let's print data after column rename\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67eb8053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_lower_limit</th>\n",
       "      <th>age_upper_limit</th>\n",
       "      <th>gender</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>21</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age_lower_limit  age_upper_limit gender  weight\n",
       "0                 0                3      0      10\n",
       "1                 4                6      0      18\n",
       "2                 7               12      0      35\n",
       "3                13               20      0      58\n",
       "4                21               32      0      60\n",
       "5                33               43      0      65\n",
       "6                44               53      0      68\n",
       "7                54              100      0      60\n",
       "8                 0                3      1       9\n",
       "9                 4                6      1      16\n",
       "10                7               12      1      30\n",
       "11               13               20      1      48\n",
       "12               21               32      1      50\n",
       "13               33               43      1      51\n",
       "14               44               53      1      53\n",
       "15               54              100      1      55"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing gender column value. male to 0 and female to 1\n",
    "df.loc[df[\"gender\"] == \"Male\", \"gender\"] = 0\n",
    "df.loc[df[\"gender\"] == \"Female\", \"gender\"] = 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f058cfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the range and get min-max\n",
    "def age_minmax_range(age_range_txt):\n",
    "    res = re.split('\\(|-|\\)', age_range_txt)\n",
    "    return (int(res[1]), int(res[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83219021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall weight\n",
    "def calculate_load(idxs, age_gender_index_list):\n",
    "    # ensure at least one detection exists\n",
    "    total_weight = 0\n",
    "    person_count = 0\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            if age_gender_index_list[i][1] >= 0:\n",
    "                # object is an human being\n",
    "                person_count = person_count + 1\n",
    "            if age_gender_index_list[i][1] >= 0 and age_gender_index_list[i][0] >= 0:\n",
    "                age_range = age_minmax_range(AGE_LIST[age_gender_index_list[i][0]])\n",
    "                # print(age_range)\n",
    "                for index in df.index:\n",
    "                    if age_range[0] >= df['age_lower_limit'][index] and age_range[1] <= df['age_upper_limit'][index] and age_gender_index_list[i][1] == df['gender'][index]:\n",
    "                        total_weight = total_weight + df['weight'][index]\n",
    "    return person_count, total_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77ab5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all required models\n",
    "\n",
    "# Load gender prediction model\n",
    "age_Net = cv2.dnn.readNet(AGE_CONFIG, AGE_WEIGHTS)\n",
    "# Load gender prediction model\n",
    "gender_net = cv2.dnn.readNetFromCaffe(GENDER_MODEL, GENDER_PROTO)\n",
    "# Load object detection prediction model\n",
    "object_detection_net = cv2.dnn.readNetFromDarknet(CONFIG_FILE, WEIGHTS_FILE)\n",
    "# determine only the *output* layer names that we need from YOLO\n",
    "ln = object_detection_net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in object_detection_net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76db0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open camera\n",
    "vs = cv2.VideoCapture(0)\n",
    "# Performance check\n",
    "fps = FPS().start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f4e4ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict age using age net\n",
    "\n",
    "def predict_age(blob):\n",
    "    age_Net.setInput(blob)\n",
    "    age_preds = age_Net.forward()\n",
    "    return age_preds[0].argmax()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089fdc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict gender using gender net\n",
    "def predict_gender(blob):\n",
    "    gender_net.setInput(blob)\n",
    "    gender_preds = gender_net.forward()\n",
    "    return gender_preds[0].argmax()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e8a2afc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# process the input video (camera feed)\n",
    "\n",
    "def process_video_input():\n",
    "    while True:\n",
    "        try:\n",
    "            (grabbed, image) = vs.read()\n",
    "        except:\n",
    "            print('Unable to read camera output. Exiting')\n",
    "            break\n",
    "        blob = cv2.dnn.blobFromImage(image, 1 / 255.0, (416, 416),\n",
    "            swapRB=True, crop=False)\n",
    "        object_detection_net.setInput(blob)\n",
    "        (image_height, image_width) = image.shape[:2]\n",
    "        layerOutputs = object_detection_net.forward(ln)\n",
    "        # initialize our lists of detected bounding boxes, confidences, and\n",
    "        # class IDs, respectively\n",
    "        object_boxes = []\n",
    "        confidences = []\n",
    "        classIDs = []\n",
    "        age_gender_index_list = []\n",
    "        # loop over each of the layer outputs\n",
    "        for output in layerOutputs:\n",
    "            # loop over each of the detections\n",
    "            for detection in output:\n",
    "                # extract the class ID and confidence (i.e., probability) of\n",
    "                # the current object detection\n",
    "                scores = detection[5:]\n",
    "                classID = np.argmax(scores)\n",
    "                confidence = scores[classID]\n",
    "                # filter out weak predictions by ensuring the detected\n",
    "                # probability is greater than the minimum probability\n",
    "                if confidence > CONFIDENCE_THRESHOLD:\n",
    "                    # scale the bounding box coordinates back relative to the\n",
    "                    # size of the image, keeping in mind that YOLO actually\n",
    "                    # returns the center (x, y)-coordinates of the bounding\n",
    "                    # box followed by the boxes' width and height\n",
    "                    box = detection[0:4] * np.array([image_width, image_height, image_width, image_height])\n",
    "                    (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                    # use the center (x, y)-coordinates to derive the top and\n",
    "                    # and left corner of the bounding box\n",
    "                    x = int(centerX - (width / 2))\n",
    "                    y = int(centerY - (height / 2))\n",
    "                    age_index = -1\n",
    "                    gener_index = -1\n",
    "                    if classID == 0 and x > 0 and y > 0 and int(width) > 0 and int(height) > 0: # Person\n",
    "                        face_box = [x, y, x+int(width), y+int(height)]\n",
    "                        face = image[face_box[1]:face_box[3], face_box[0]:face_box[2]]\n",
    "                        # ----- Image preprocessing --------#\n",
    "                        blob = cv2.dnn.blobFromImage(\n",
    "                            face, 1.0, (227, 227), MODEL_MEAN, swapRB=False)\n",
    "                        # Age Prediction\n",
    "                        age_index = predict_age(blob)\n",
    "                        # Predict Gender\n",
    "                        gener_index = predict_gender(blob)\n",
    "                    # update our list of bounding box coordinates, confidences,\n",
    "                    # and class IDs\n",
    "                    object_boxes.append([x, y, int(width), int(height)])\n",
    "                    age_gender_index_list.append([age_index, gener_index])\n",
    "                    confidences.append(float(confidence))\n",
    "                    classIDs.append(classID)\n",
    "        # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        idxs = cv2.dnn.NMSBoxes(object_boxes, confidences, CONFIDENCE_THRESHOLD, CONFIDENCE_THRESHOLD)\n",
    "\n",
    "        # ensure at least one detection exists\n",
    "        if len(idxs) > 0:\n",
    "            # loop over the indexes we are keeping\n",
    "            for i in idxs.flatten():\n",
    "                # extract the bounding box coordinates\n",
    "                (x, y) = (object_boxes[i][0], object_boxes[i][1])\n",
    "                (w, h) = (object_boxes[i][2], object_boxes[i][3])\n",
    "\n",
    "                color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "\n",
    "                cv2.rectangle(image, (x, y), (x + w, y + h), color, 2)\n",
    "                text = \"{}\".format(LABELS[classIDs[i]])\n",
    "#                 if age_gender_index_list[i][1] >= 0:\n",
    "#                     text = \"{}, {}\".format(text, GENDER_LIST[age_gender_index_list[i][1]])\n",
    "#                 if age_gender_index_list[i][0] >= 0:\n",
    "#                     text = \"{}, Age - {}\".format(text, AGE_LIST[age_gender_index_list[i][0]])\n",
    "                cv2.putText(image, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, color, 2)\n",
    "        text = \"No of objects: {}\".format(len(idxs))\n",
    "        no_person, total_weight = calculate_load(idxs, age_gender_index_list)\n",
    "        if total_weight > TOTAL_BEARING_CAPACITY:\n",
    "            # send alert message, audio/visual message.\n",
    "            print(f'Exceed capacity. No of person - {no_person}. Bearing capacity - {TOTAL_BEARING_CAPACITY}. Total estimated wt - {total_weight}')\n",
    "            play_alert_sound()\n",
    "        cv2.putText(image, text, (15, 15), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (255, 255, 255), 2)\n",
    "        # show the output image\n",
    "        cv2.imshow(\"output\", cv2.resize(image,(800, 600)))\n",
    "        fps.update()\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord(\"q\"):\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20584ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release all the occupied resources\n",
    "def release_video_input():\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "    # do a bit of cleanup\n",
    "    cv2.destroyAllWindows()\n",
    "    # release camera\n",
    "    vs.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf289cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 207\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 217\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 163\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 193\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 161\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 175\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 234\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 173\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 172\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 242\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 354\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 323\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 165\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 253\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 171\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 235\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 235\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 216\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 230\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 218\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 218\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 249\n",
      "Exceed capacity. No of person - 4. Bearing capacity - 150. Total estimated wt - 185\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 235\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 299\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 392\n",
      "Exceed capacity. No of person - 8. Bearing capacity - 150. Total estimated wt - 423\n",
      "Exceed capacity. No of person - 8. Bearing capacity - 150. Total estimated wt - 422\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 330\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 375\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 317\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 326\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 332\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 289\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 391\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 285\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 317\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 368\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 283\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 284\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 371\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 322\n",
      "Exceed capacity. No of person - 8. Bearing capacity - 150. Total estimated wt - 423\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 373\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 376\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 318\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 332\n",
      "Exceed capacity. No of person - 7. Bearing capacity - 150. Total estimated wt - 387\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 316\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 247\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 316\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 314\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 316\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 316\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 321\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 322\n",
      "Exceed capacity. No of person - 5. Bearing capacity - 150. Total estimated wt - 268\n",
      "Exceed capacity. No of person - 6. Bearing capacity - 150. Total estimated wt - 327\n",
      "Exceed capacity. No of person - 3. Bearing capacity - 150. Total estimated wt - 160\n"
     ]
    }
   ],
   "source": [
    "# let's execute\n",
    "if __name__ == '__main__':\n",
    "    process_video_input()\n",
    "    release_video_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d38b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b0a3fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "183px",
    "width": "226px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
